lamb: 0.1
lamb_intra: 0.2
learning_rate: 5.0e-05
lm: 10
margin: 0.05
num_train_epochs: 11
objective: 0.8794186959937156
per_device_train_batch_size: 32
weight_decay: 0.1
