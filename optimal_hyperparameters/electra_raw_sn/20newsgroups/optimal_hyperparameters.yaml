lamb: 0.02
lamb_intra: 0.002
learning_rate: 3.0e-05
margin: 0.05
num_train_epochs: 12
objective: 0.896700706991359
per_device_train_batch_size: 64
weight_decay: 0
